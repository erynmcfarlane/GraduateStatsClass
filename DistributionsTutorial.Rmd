---
title: "Distributions for All"
author: "Eryn McFarlane"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Videos I've used for this:
https://www.youtube.com/watch?v=UrOXRvG9oYE
https://www.youtube.com/watch?v=BPlmjp2ymxw
https://www.youtube.com/watch?v=v1uUgTcInQk
https://www.youtube.com/watch?v=CEVELIz4WXM

##other references
https://www.zoology.ubc.ca/~bio301/Bio301/Lectures/Lecture25/Overheads.html


### Need to turn this into a tutorial where there are questions they need to answer at the end!

#Distributions!


I want to talk about a bunch of distributions, and then I want to simulate them as we go so people can see what I'm talking about. 

1) Bernoulli - the distribution of the number of successes on a single Bernoulli trial.
This is what we were talking about last week, for example survival at a single time point. 0 or 1, not a bunch of 0's or 1's (that would be binomial). If we toss a coin once, what's the probability of it being heads? Special case of binomial, n=1

2) Binomial distribution is multiple Bernoulli trials - if a coin is tossed 20 times, what is the probability that heads comes up xx/20? How many patients in this ER have covid? What about in this classroom? Discrete space/time. 

```{r Bernoulli}
#### Eryn - note to yourself that the fun thing to do here would be to change the different variables for each simulation and see how they look difference in the plots!
trials<-0:100 ## 1000 Bernoulli trials
plot(trials, dbinom(trials, size=100, prob=0.5), type='h')
```
```{r Binomial}
chicks<-rbinom(100,6, 0.05) ## let's say 100 nests, 6 chicks per next (typically), 5% survival rate. 
hist(chicks)
```

3) geometric distribution is the distribution of the number of trials needed to get the first success. How many times do I have to flip a coin to get a heads? How many patients do I have to test before one has covid? E.g/ if a coin is repeatedly tossed, what is the probability the first time heads occurs is on the 8th toss? Can be thought of as the spacing between neighbours. How many more tests until I get another positive case?
```{r Geometric}
geom_chicks<-rgeom(100, 0.05) # this gives back the number of failures before the first successs in each of 10 trials. In our chick example, this could be how many kids each of 10 sets of parents need to have before they successfully recruit one. 
hist(geom_chicks, breaks = seq(min(geom_chicks), max(geom_chicks), length.out=21))
```

4) Negative binomial - distribution of the number of trials needed to get a certain number of successes. How many random people do we need on a plane to be fairly sure there's some medical doctors (whereas the geometic is how many to be sure there's one)? If a coin is repeatedly tossed, what is the probability the 3rd time a heads appears is on the 9th trial? Rather than the spacing between neighbours, can think of this as the spacing of any number of things in reference category. 
Generalizes from the geometric. Geometric is to the the 1st success, negative binomial is to get the rth success. Bolker basically says that this is not the way that ecologists think of the negative binomial - rather, we like it because it's independent counts of successes, like poisson, but allows for overdispersion. 

```{r Negative Binomial}
library(MASS)
negbinomial_singers<-MASS::rnegbin(100, mu=5, theta=10) # To carry our flycatcher example forward, negative binomial could be what is the number of singing males we see over a week (as opposed to alarm calling or otherwise not singing). n=# of sites we visit (or site-weeks), mu= mean, theta= measure of over dispersion. If mu = theta, you have poisson distribution (according to here: https://stats.stackexchange.com/questions/10419/what-is-theta-in-a-negative-binomial-regression-fitted-with-r)
hist(negbinomial_singers)
```

Binomial vs Negative Binomial
Binomial - number of trials is fixed (n), number of successes is a random variable.
Negative Binomial - number of successes is fixed (r), number of trials is the random variable (x)

5) Poisson- The probability of a given number of events occuring in a fixed time interval. Closely approximates the binomial if n is very large and the probablity of success, p, is very small. Counts, like binomial, but not assuming independence, and in continuous space/time. Mean and the variance are the same (which is why when you know you have overdispersed data, you're encouraged to use the negative binomial.) The Poisson only makes sense for count data. 

```{r Poisson}
pois_chicks<-rpois(100, 6.5) # number of chicks produced in a season, or a life time. I've used the poisson for LRS or ARS, but good arguements could be made for zero-inflated poisson (which I am NOT going to talk about. )
hist(pois_chicks)
```

6) Exponential distribution - waiting time for a single event to happen, given that there's a constant probability per unit time. Time until death, where instantaneous death rate is lambda. Isn't this where the covid R0 comes from - time until doubling?

```{r Exponential}
exp<-rexp(100, 0.5) ##time until death, where instantaneous death rate is lambda
hist(exp)
```


7) Gamma distribution - waiting time to any number of positive cases (for rth occurance at a rate lambda). This is a continuous distribution, and is the continuous counter part of the negative binomial. This generalized the exponential distribution with a clear right skew. For example, how many days until we've had 20 eggs laid in the population.

```{r Gamma}
gamma<-rgamma(100, shape=100, scale=0.5) ##time until death, where instantaneous death rate is lambda
hist(gamma)
```


8) Beta distribution - probability of success (in contrast to number of successes, which is what the binomial models). Trivia Answer - what is Alex Buerkle's favourite distribution? Has two  parameters (a and b) to describe the distribution, which can basically be anything between 0 and 1 (but excluding both). For example, allele frequencies are well characterized by the beta distribution. Continuous distribution. This allows you to model anything that looks like a probability. 
If a=0.5 and b=0.5, you get a u shape. If a and b are not the same, the distribution isn't symetrical. If a and b both =1, you get the uniform probability density. 


```{r Beta}
beta_chicks<-rbeta(100, 5, 5) ## My chick example isn't working for me as well right now. But, something like distribution of admixed hybrids (from two populations) is well approximated by beta. So let's say we have two interbreeding populations, and we want to know what the proportion of species A is in each individual. Beta's great for that. 
hist(beta_chicks)
```


9) Dirichlet distribution- generalization of the beta distribution. Give k probabilities (instead of just over two things like in beta) that sum to 1. Parameter of the dirichlet distribution is a vector, of k length. 

```{r dirichlet}
library(dirmult)
library(ggplot2)
dir<-rdirichlet(n=100, alpha=rep(1,3)) ## example includes metabarcoding, rnaseq. Anything that must sum up to one. 
## no idea how to plot this!

```

10) Weibull distribution - heavily tailed gamma, waiting time for failure








